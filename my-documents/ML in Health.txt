Machine Learning in Healthcare
Hafsa Habehh 1, Suril Gohel 1,*
Author information
Article notes
Copyright and License information
PMCID: PMC8822225  PMID: 35273459
Abstract
Recent advancements in Artificial Intelligence (AI) and Machine Learning (ML) technology have brought on substantial strides in predicting and identifying health emergencies, disease populations, and disease state and immune response, amongst a few. Although, skepticism remains regarding the practical application and interpretation of results from ML-based approaches in healthcare settings, the inclusion of these approaches is increasing at a rapid pace. Here we provide a brief overview of machine learning-based approaches and learning algorithms including supervised, unsupervised, and reinforcement learning along with examples. Second, we discuss the application of ML in several healthcare fields, including radiology, genetics, electronic health records, and neuroimaging. We also briefly discuss the risks and challenges of ML application to healthcare such as system privacy and ethical concerns and provide suggestions for future applications.

Keywords: Machine learning, healthcare, support vector machine, EHR, genomics, artificial intelligence

1. INTRODUCTION
The application of machine learning dates back to the 1950s when Alan Turing proposed the first machine that can learn and become artificially intelligent [1]. Since its advent, machine learning has been used in various applications, ranging from security services through face detection [2] to increasing efficiency and decreasing risk in public transportation [3, 4], and recently in various aspects of healthcare and biotechnology [5-10]. Artificial intelligence and machine learning have brought significant changes in business processes and have transformed day-to-day lives, and comparable transformations are anticipated in healthcare and medicine. Recent advancements in this area have displayed incredible progress and opportunity to disburden physicians and improve accuracy, prediction, and quality of care. Current machine learning advancements in healthcare have primarily served as a supportive role in a physician or analyst's ability to fulfill their roles, identify healthcare trends, and develop disease prediction models. In large medical organizations, machine learning-based approaches have also been implemented to achieve increased efficiency in the organization of electronic health records [11], identification of irregularities in the blood samples [5], organs [6-8], and bones [12] using medical imaging and monitoring, as well as in robot-assisted surgeries [9, 13]. Machine learning applications have recently enabled the acceleration of testing and hospital response in the battle against COVID-19. Hospitals have been able to organize, share, and track patients, beds, rooms, ventilators, EHRs, and even staff during the pandemic using a deep learning system by GE called the Clinical Command Center [14]. Researchers have also used artificial intelligence for the identification of genetic sequences of SARS-CoV2 and the creation of vaccines as well as for their monitoring [15].

Many new developments emerge as the field of healthcare grows into the new world of technology. Artificial intelligence and machine learning-based approaches and applications are vital for the field’s progression, including increased speed of diagnosis, accuracy, and simplicity. The purpose of this review is to highlight the advantages and disadvantages of machine learning-based approaches in the healthcare industry. As the application of new machine learning technology takes the healthcare industry by storm, we aim to provide a brief overview of the various approaches to machine learning and highlight the fields where these approaches are primarily applied. We discuss their widespread use and future advancement opportunities in healthcare. We also address the ethical and logistical risks and challenges that occur with their application.

2. OVERVIEW OF ARTIFICIAL INTELLIGENCE
Although the terms machine learning, deep learning, and artificial intelligence are typically used interchangeably, they represent different sets of algorithms and learning processes. Artificial Intelligence (AI) is the umbrella term that refers to any computerized intelligence that learns and imitates human intelligence [16]. AI is most regarded for autonomous machines such as robots and self-driving cars, but it also permeates everyday applications, such as personalized advertisements and web searches. In recent years, AI development and application have made incredible strides and have been applied to many areas due to their higher levels of decision-making, accuracy, problem-solving capability, and computational skills [17]. In generally all development of AI algorithms, the data obtained is split into two groups, a training and test data set, to ensure reliable learning, representative populations, and unbiased predictions. As the name suggests, the training set is used for algorithm training that includes sets of characterizing data points (features) and corresponding predictions (in the case of supervised learning). The testing data set is new to the algorithm and is solely used to test the algorithm's abilities. This measure is taken to eliminate biases in the algorithm's testing by the training dataset [18]. Once an algorithm passes through a training and testing phase with acceptable results, the algorithms are implemented in healthcare settings. The application of AI is broad and has many applied sub-regions; here, we provide an overview of machine learning and deep learning, two of the several sub-regions of AI.

Machine learning encompasses several different algorithmic models and statistical methods to solve problems without specialized programming [19]. Several machine learning models are single-layered, therefore, large components of feature extraction and data processing are performed prior to inputting the data into the algorithm [20]. Without the extra layers, these machine learning algorithms require intense data preprocessing in order for the algorithms to determine accurate predictions and to avoid over-fitting or under-fitting the training dataset. Deep learning is a more elaborate sub- form of machine learning that utilizes layered artificial neural networks and provides increased accuracy and specificity with decreased interpretability [21]. The neuronal network method is characterized as the multilayer network that supports the connection between the artificial neurons, or units, in each layer with that of the layer before and after it [22]. These networks can learn, discern, and deduce from data on their own using these multilevel links for data processing, and the data are processed until the specialized results are achieved [21].

2.1. Types of Learning Approaches
Most of the machine learning and AI-based algorithms are built on different learning approaches. One subtype is supervised learning, which is used in training classification and prediction algorithms based on previous examples, or outputs. An important distinction for this learning technique is that the training set involves features and corresponding predictions, or outcomes. Simply put, the supervised learning approach generalizes information from the training set's features to construct a model that can correctly predict training-set outcomes and then uses the learned model to make predictions using the new features in the testing data set [20]. Decision Trees, Random Forest, Support Vector Machines, and Artificial Neural Networks are a few types of ML algorithms that implement supervised learning approaches. Decision tree algorithms form a decision support tool that begins with a single node and identifies the possible outcomes of that decision. The tree continues with the product of that decision and the following decisions until it reaches a final product [23]. Support Vector Machines (SVM) are known as classification algorithms that use supervised learning to classify features in two group problems by finding the largest margin hyperplane to separate the data and providing the best fit to organize it [16, 24]. Artificial Neural Networks (ANNs) consist of an input layer, one or more hidden layers, and output layers, where functional unities/neurons in one layer are connected to every neuron in the layer before and after [25]. In healthcare, supervised machine learning approaches are widely implemented in disease prediction [26], identifying hospital outcomes [14], and image detection [27] to name a few.

Another subtype of AI-based learning approaches is unsupervised learning, which is typically used to evaluate data and to cluster applications. Unsupervised machine learning is usually purposeful in data analysis, stratification, and reduction rather than prediction. In general, unsupervised clustering methods use algorithms to group data that has not been classified or categorized into independent clusters. Although data preprocessing and feature extraction are done before the input in most forms of machine learning, this method allows for the extraction of features and explores possibilities of data clusters by identifying the underlying relationships or features in the data, then grouping them by their similarities [18]. Some unsupervised learning approaches include the k-Means algorithm, Deep Belief Networks, and Convolutional Neural Networks. The most common unsupervised learning algorithm is the k-Means algorithm that is used as a clustering method to identify the mean between groups within unlabeled datasets and create groups based on the mean [18]. A Deep Belief Network (DBN) is a multi-layer network consisting of intra-level connections useful for data retrieval that typically uses unsupervised learning and has many hidden layers tasked with feature detection and finding correlations in the data [28, 29]. A Convolutional Neural Network (CNN) is a multilayer network that relies on feature recognition and identification and is useful for anomaly detection, image recognition, and identification [25]. Many unsupervised algorithms are used for clustering due to the lack of predetermined results and homogeneity in the data, and although the unsupervised methods are useful and quick, they are only semipopular in healthcare.

Reinforcement learning is another learning method that is neither supervised nor unsupervised learning. Similar to the mechanisms of conditioning in psychology, this learning depends on the sequences of rewards, and it forms a strategy for operation in a specific problem space. Reinforcement learning methods have the potential to influence their environment, are geared towards optimizing the error criterion, and have been described as the closest form of learning as seen in humans and animals [30]. Given the types of learning approaches, the selection of learning methods is relatively less complicated than the selection of algorithms and is usually dictated by the implementation purpose. A commonly used neural network that uses reinforcement learning is the Recurrent Neural Network (RNN). An RNN is one of the neural networks in which every artificial neuron is connected; the artificial neurons can receive inputs with delays in time and can reuse outputs from previous steps as input for a future step. It is useful for time series prediction, translation, speech recognition, rhythm learning, and music composition [25]. Although healthcare applications of reinforcement learning remain limited due to its need for structure, heterogeneous data, definition and implementation of rewards, and extensive computational resources, it still possesses the significant potential to bring major strides in healthcare.

Given the several types of machine learning and deep learning approaches, it is highly imperative to identify and implement an approach suitable specific to the healthcare application. Several factors, including the number of features [28], sample size [31, 32], and data distributions [33], can have significant effects on the learning and prediction processes and should be considered.

3. AI IN HEALTHCARE
In healthcare, common machine learning advances have been evolving for years. The application of AI has the capacity to assist with case triage and diagnoses [26], enhance image scanning and segmentation [34], support decision making [11], predict the risk of disease [35, 36], and in neuroimaging [37]. Here we provide a brief overview of current advances in AI applications to specific aspects of health science. Inclusion criteria for the applications mentioned are based on the higher availability of digital data used in the ML-based approaches and their clear implementation of learning approaches with clinical applications and experiments. In the current review, we focused on ML application to healthcare in the fields of electronic health records, medical imaging, and genetic engineering. These areas also represent healthcare’s “BIG” data, or the structured and unstructured data of the field, and have shown significant promise in relation to clinical applications.

Our search strategy is as follows: articles between June and December 2020, online libraries and journal databases including, but not limited to, and Academic OneFile, Gale, Nature, Sage Journals, Science Direct, PsycNet, and Pubmed were used. The compilation of articles and papers focused on the use of machine learning and artificial intelligence in healthcare as well as current and potential applications. Search terms included machine learning in healthcare, artificial intelligence medical imaging, BIG data and machine learning, machine learning in genomics, electronic health records, challenges of AI in healthcare, and medical applications of AI. Variations of these terms were used to ensure exhaustive search results. Searches were not limited by year or journal Table 1.

Table 1.
List of primary references.

Healthcare Area	Type of Machine Learning Model	Description	Applied or Experiment	References
EHRs	SVM, DT	Using EHRs for predicting diagnoses	Applied	Liang et al. 2014 [26]
-	RNN	Predicting post-stroke pneumonia using deep neural network approaches	Experiment	Ge et al., 2019 [35]
-	LSTM, CNN	Deep EHR: Chronic Disease Prediction Using Medical Notes	Experiment	Liu, Zhang & Razavian 2018 [40]
-	ML	SRML-Mortality Predictor: A hybrid machine learning framework to predict mortality in paralytic ileus patients using Electronic Health Records (EHRs)	Experiment	Ahmad et al., 2020 [41]
Medical Imaging	CNN	Dermatologist-level classification of skin cancer with deep neural networks	Experiment	Esteva et al. 2017 [7]
-	CNN	Chexnet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep-Learning	Applied	Rajpurkar et al., 2017; Tsai & Tao, 2019 [8]
-	CNN	International evaluation of an AI system for breast cancer screening	Experiment	McKinney et al. 2020 [49]
-	Deep CNN	Deep-learning algorithm predicts diabetic retinopathy progression in individual patients	Experiment	Arcadu et al. 2019 [56]
-	DBN	Structural MRI classification for Alzheimer's disease detection using deep belief network	Experiment	Faturrahman et al., 2017 [37]
-	Decision tree	Machine learning approaches for integrating clinical and imaging features in late-life depression classification and response prediction	Experiment	Patel et al., 2015 [27]
Genetic Engineering & Genomics	RT	Application of machine learning models to predict tacrolimus stable dose in renal transplant recipients	Experiment	Tang et al. 2017 [10]
-	ML	Artificial intelligence predicts the immunogenic landscape of SARS-CoV-2 leading to universal blueprints for vaccine designs	Applied	Malone et al. 2020 [15]
-	Deep CNN, Deep FFs	Off-target predictions in CRISPR-Cas9 gene editing using deep learning	Applied	Lin & Wong 2018 [76]
-	RNNs	DeepHF: Optimized CRISPR guide RNA design for two high-fidelity Cas9 variants by deep learning	Applied	Wang et al., 2019 [85]
-	Random Forest	CUNE: Unlocking HDR-mediated nucleotide editing by identifying high- efficiency target sites using machine learning	Applied	O’Brien et al., 2019 [86]
-	CNNs	ToxDL: deep learning using primary structure and domain embeddings for assessing protein toxicity	Applied	Pan et al., 2020 [87]
Open in a new tab
Applied is defined as an algorithm or application that is currently available on a public or private platform to healthcare professionals. It also refers to applications that are currently applied in medical practices such as clinics, hospitals, etc. An experiment is defined as an algorithm or application that has been used in a research study. EHR: Electronic Health Records, SVM: Support Vector Machine, LSTM: Long Short-Term Memory Neural Network, CNN: Convolutional Neural Network, MLP: Multi-Layer perceptron Neural Network, RNN: Recurrent Neural network, DBN: Deep Belief Network, ANN: Artificial Neural Network, ML: Machine Learning.

3.1. Electronic Health Records
Electronic Health Records (EHRs), originally known as clinical information systems, were first introduced by Lockheed in the 1960s [38]. Since then, the systems have been reconstructed many times to create an industry-wide standard system. In 2009, the US federal government invested billions in promoting EHR implementation in all practices in an effort to improve the quality and efficiency of the work; this ultimately resulted in nearly 87 percent of office-based practices nationwide implementing EHRs in their systems by 2015 [39]. BIG data collected from EHR systems with structured feature data have been instrumental in deep learning applications, including medication refills and using patient history for predicting diagnoses [11]. This has resulted in significant improvement in data organization, accessibility, and quality of care and has helped physicians with diagnoses and treatments. The standardization of features across datasets has also allowed for increased access to health records for research purposes.

Considering the vital role that prediction plays in providing treatment, scientists have developed deep learning models for the diagnosis and prediction of clinical conditions using EHRs. In a recent research study, Liu, Zhang, and Razavian developed a deep learning algorithm using LSTM networks (reinforcement learning) and CNNs (supervised learning) to predict the onset of diseases, such as heart failure, kidney failure, and stroke. Unlike other prediction models, this algorithm used both structured data obtained from EHR and unstructured data contained in progress and diagnosis notes. As explained by Liu and colleagues, the inclusion of unstructured data within the model resulted in significant improvements in all the baseline accuracy measures, further indicating the versatility and robustness of such algorithms [40]. In another research study using deep neural network approaches, Ge and colleagues built a model to predict post-stroke pneumonia within 7 and 14-day periods. The model returned an Area under the ROC curve (AUC, a measure of model performance by combining sensitivity and specificity of a model) value of 92.8 percent for the 7-day predictions and 90.5 percent for the 14-day predictions [35], providing a highly accurate model predicting pneumonia following a stroke. In addition, several ML-based models have also been implemented to predict mortality in ICU patients. In one of such models, Ahmad and colleagues have shown great ability to predict mortality in paralytic ileus (PI, incomplete blockage of the intestine that prohibits the passage of food, eventually leading to a build-up and complete blockage of the intestines) patients using EHRs. The algorithm, named Statistically Robust Machine Learning-based Mortality Predictor (SRML-Mortality Predictor), showed an 81.30% accuracy rate in predicting mortality in PI patients [41]. Providing patients and practitioners with predicted mortality, through the use of EHR prediction algorithms, can allow them to make more educated clinical treatment decisions.

3.2. Medical Imaging
Given the digital nature of data and the presence of structured data formats such as DICOM (Digital Imaging and Communications in Medicine), medical imaging has seen significant strides with the implementation of machine learning-based approaches to several imaging modalities, including Computed Tomography (CT), Magnetic Resonance Imaging (MRI), X-Ray, Positron Emission Tomography (PET), Ultrasound, and more. Several ML-based models have been developed to identify tumors [42, 43], lesions [44], fractures [45, 46], and tears [47, 48].

In a recent study, McKinney and colleagues have implemented a deep learning algorithm to detect tumors based on Mammograms in earlier stages of growth. In comparison to traditional screening techniques used to identify tumors, these deep learning-based screen techniques allow for the identification and location of tumors in earlier stages of breast cancer, allowing for a better rate of resection. In a direct comparison, the deep learning-based approach was able to outperform experienced radiologists by an AUC score of 11.5% [49]. Several other studies have also implemented ML-based approaches for breast cancer detection with variable success, including models by Wang and colleagues [50], Amrane and colleagues [51], and Ahmad and colleagues [52].

Similarly, in a recent study, Esteva and colleagues used CNN (unsupervised learning) to classify 2032 different skin diseases using dermoscopic images. An objective comparison of CNN classification with that of 21 board-certified dermatologists resulted in “on par” performance, further confirming the veracity of the results [7]. When implemented in conjunction with the average consumer mobile platform, this approach can result in ease of use and early diagnosis. In parallel, studies have also implemented ML-based approaches to quantify the progression of retinal diseases [51-54]. In one such study, Arcadu and colleagues applied a deep learning CNN to detect the aneurysms that cause vision loss due to the progression of Diabetic Retinopathy (DR) [55]. The CNN was also able to detect small and low contrast microaneurysms, although it was not explicitly designed to accomplish that task [55, 56]. Given that diabetic retinopathy is a common eye condition that affects around 60 percent of type 1 diabetes patients [57], it is difficult to detect in its preliminary stages. Early prediction obtained using a CNN approach has the potential to prevent and delay irreversible damage to patients' vision. X-rays have been used for decades to identify abnormalities in the chest cavity and lung disease, though an in-depth careful examination by a training radiologist is often required. In a recent study, Rajpurkar and colleagues conducted a retrospective study to explore the capacities of a 121-layer convolutional neural network to examine a collection of chest x-rays with various thoracic diseases and identify irregularities in an attempt to mimic the detection by trained radiologists [8]. In comparison, CNN's performance in the accuracy of identification observed was 81%, which was 2% higher than that of the radiologists. Although applied retrospectively, this study, along with CNNs developed by Tsai and Tao [58], Asif and colleagues [59], Liang and colleagues [60], and Lee and colleagues [61], indicates incredible support that these approaches can provide in examining and diagnosing illnesses, further reducing the burden on healthcare professionals.

ML-based approaches have also been implemented to predict and diagnose disease progression of neurodegenerative diseases, including Alzheimer's disease [37, 62], Parkinson's disease [63, 64], serious mental disorders including Psychosis, [65, 66], depression [27, 67], PTSD [68], and developmental disorders, including autism [69, 70] and ADHD [71, 72]. In one such study, Faturrahman and colleagues presented a higher-level model using DBNs(unsupervised learning) for predicting Alzheimer's Disease (AD) progression using structural MRI images, resulting in 91.76% accuracy, 90.59% sensitivity, and 92.96% specificity [37]. Although there is no cure for AD, early diagnosis can help implement strategies to delay the symptoms and degeneration. Using decision tree models and feature-rich data sets consisting of functional MRI, cognitive behavior scores, and age, Patel and colleagues developed a model to predict the diagnosis and treatment response for depression. The model scored 87.27% accuracy for diagnosis and 89.47% accuracy for treatment response [27]. This predictive diagnosis can help identify patients with depression and develop personalized treatment plans based on their responses. With the current ML applications in medical imaging, it is evident that its use has valuable implications for advancing the medical field due to its pronounced advantages in accuracy, classification, sensitivity, and specificity in prediction and diagnoses.

3.3. Genetic Engineering and Genomics
The discovery of the adaptive DNA system known as CRISPR (Clustered Regularly Interspaced Short Palindromic Repeats) has cultivated the field of genetic engineering [73]. This exploration of “programmable endonucleases” has simplified genetic engineering and has helped make the process of genetic modification and diagnosis easier, as well as dropping the cost of the procedure dramatically [74]. The recent application of CRISPR to Cas (CRISPR-associated protein) editing, such as Cas-9 [75] and Cas-13a [73], has changed genetic editing, though the tool is not perfect. Recently, several machine learning techniques for predicting off-target mutations in Cas9 gene editing have emerged. A new program developed by Jiecong Lin and Ka-Chun Wong has improved the quality of these machine learning predictions by using deep CNNs (AUC score: 97.2%) and deep FFs (AUC score: 97%) [76]. Considering the space for error and off-target mutations using the Cas9 tool, scientists are using Cas9 for developing activity predictors and more reliable Cas9 variants to reduce error. These models include higher accuracy and fidelity Cas9 variants [77-79], hyper-accurate Cas9 variants [80], and guide RNA design tools using deep learning [81-85].

Outside of CRISPR gene editing, O'Brien and colleagues have developed a service to provide efficiency in nucleotide editing using random forest algorithms (supervised learning) to investigate how different nucleotide compositions influence the HDR (homology-directed repair) efficiency [86]. They developed the Computational Universal Nucleotide Editor (CUNE), used to find the most efficient method to identify a precise location to enter a specific point mutation and predict HDR efficiency. Additionally, Pan and colleagues have developed a model for prediction in gene editing named ToxDL that uses a CNN approach to predict protein toxicity in-vivo using only the sequence data [87]. Another branch of genetic engineering, pharmacogenomics, has also made significant strides in the use of AI and machine learning to determine stable doses of medications that have become popular [88-90]. In one such study, Tang and colleagues implemented an ML-based approach to determine a stable Tacrolimus dose (the immunosuppressive drug) for patients who received a renal transplant to reduce the risk of acute rejection [10]. The use of machine learning in pharmacogenomics has recently been applied in psychiatry [90], oncology [91], bariatrics [92], and neurology [93].

Machine learning applications of genetic engineering have also been instrumental in the fight against COVID 19. In a recent study, Malone and colleagues utilized software based on machine learning algorithms to “predict which antigens have the required features of HLA-binding, processing, presentation to the cell surface, and the potential to be recognized by T cells to be good clinical targets for immunotherapy” [15]. The use of immunogenicity predictions from this software, along with the presentation of antigen to infected host-cells, allowed the team to successfully profile the “entire SARS-CoV2 proteome” as well as epitope hotspots. These discoveries help predict blueprints for designing universal vaccines against the virus that can be adapted across the global population.

4. RISKS AND CHALLENGES
While machine learning-based applications in healthcare present unique and progressive opportunities, they also raise unique risk factors, challenges, and healthy skepticism. Here we discuss the main risk factors including the probability of error in prediction and its impact, the vulnerability of the systems' protection and privacy, and even the lack of data availability to obtain reproducible results. Some of the challenges include ethical concerns, loss of the personal element of healthcare, and the interpretability and practical application of the approaches to bedside setting.

One of the most important risks of machine learning-based algorithms is the reliance on the probabilistic distribution and the probability of error in diagnosis and prediction. This also gives rise to a healthy skepticism related to the validity and veracity of predictions from ML-based approaches. Even though the probability of error and reliance on probability is deep-rooted in the various aspects of health care, the implications of ML-based approaches resulting in a human fatality are severe. One solution is to subject these machine learning-based approaches to strict institutional and legal approval by several organizations before their application [94, 95]. Another approach that can be implemented is the human intervention and oversight from an experienced healthcare worker in highly sensitive applications to avoid false-positive or false-negative diagnoses (e.g., diagnosis of depression or breast cancer). The inclusion of present healthcare professionals in developing and implementing these approaches may increase adaption rates and decrease concerns related to fewer employment opportunities for humans or the shrinking of the workforce [96].

Another risk associated with the application of ML and deep learning algorithms to health care is the availability of high-quality training and testing data with large enough sample sizes to ensure high reliability and reproducibility of the predictions. Given that the ML and deep learning-based approaches 'learn' from data, the importance of quality data cannot be stressed enough. In addition, the large amounts of feature-rich data required for these learning networks and approaches are not readily available and may also represent a narrow distribution of the population sample. Moreover, in several healthcare segments, data collected are incomplete, heterogeneous, and have a significantly higher number of features than the number of samples. These challenges should be taken into great consideration when developing and interpreting the results of ML-based approaches. The open science and recent push towards research data sharing may assist in overcoming such challenges. One should also consider the risk associated with privacy as well as ethical implications of the application of ML-based approaches to healthcare. With the understanding that these approaches require large-scale, easily expandable data storage, and significantly high computing power, several ML-based approaches are developed and implemented using cloud-based technologies. Given the sensitive nature of healthcare data along with privacy concerns, increased data security and accountability should be one of the first aspects to be considered well before model development.

With respect to ethical concerns, researchers working on applying ML-based approaches to healthcare can readily learn from the field of genetic engineering which has undergone extensive ethical debate. The controversy surrounding the use of genetic engineering to create long-lasting genetic advancements and treatments is a continuous discourse. Identification and editing of injurious genetic mutations, such as the HTT mutation that causes Huntington’s disease, may provide life-altering treatment for harmful diseases [97]. Contrarily, creating treatments that alter the individual’s genome, as well as that of their offspring, while it is still inaccessible due to costs, may worsen the socio-economic divide for populations that are unable to afford such care [98]. Recently, there has been an emergence of guidelines for the development of AI machinery. In 2019, Singapore proposed a Model Artificial Intelligence Governance Framework to guide private sector organizations on developing and using AI ethically [99]. The US Administration has also released an executive order to regulate AI development and “maintain American leadership in artificial intelligence” [100]. These guidelines and regulations, though strict, have been put forth to ensure ethical research conduct and development.

An important challenge with ML application to healthcare is associated with the interpretation and clinical applicability of the results. Given the complex structure of ML-based approaches, especially deep learning-based methods, it becomes incredibly complex to distinguish and identify the original features' contribution towards the prediction. Although this may not present significant concern in other applications of ML (such as web searches), lack of transparency has created a huge barrier for the adaptability of ML-based approaches in healthcare. As clearly understood in healthcare, the solution strategy is as important as the solution itself. There must be a systematic shift towards identifying and quantifying underlying data features used for prediction. The involvement of physicians and healthcare professionals in the development, implementation, and testing of ML-based approaches may also help improve the adoption rates. Additionally, although there is healthy skepticism related to the potential of a decreased personal relationship between a patient and PCP due to increased implementation of ML-based approaches, they represent a unique opportunity to increase engagement. Studies have shown that the physician-patient relationship has already become a fading concept, and nearly 25 percent of Americans do not have a PCP [101]. Here, ML can provide unique opportunities to increase engagement where patients discuss the results of potential diagnoses and increase the efficiency of outreach programs. Early prognosis due to ML-based approaches may also help patients develop a healthy lifestyle in consultations with their PCPs. Finally, a physician-focused survey found that 56 percent of physicians were spending 16 minutes or less with their patients, and 5 percent of them spent less than 9 minutes [102]. The application of AI approaches in diagnoses and symptom monitoring can ease stress and give physicians more personal time with their patients, thus improving patient satisfaction and outcomes.

CONCLUSION
While the overview demonstrates how much progress has been achieved with machine learning, there continues to be potential for widescale advancement in the future. Many of the current machine learning advancements in healthcare aim to support the physician’s or specialist's ability to provide a more effective treatment to patients with increased quality, speed, and precision. The challenges of developing ML algorithms can be solved by developing and implementing improvements in data collection, storage, and dissemination or by creating algorithms to process unstructured data to address the lack of data availability. Future applications can also bring forth inexpensive forms of medical imaging and affordable medical examinations, potentially ending health disparities and creating more accessible services for countries and lower-income populations. Scientists expect advancement in the prediction of personalized drug response, optimization of medication selection and dosage, and an application of genetic modification to provide treatment for genetic disorders and mutations [103]. With its application, ML can augment the role of physicians and redefine patient care. While the risks and challenges of the future application are addressed and corrected, the current ML algorithms can provide an excellent framework for future advancements and applications of ML in healthcare.

